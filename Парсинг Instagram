import requests
from bs4 import BeautifulSoup
import json
from urllib.request import urlopen


import pandas as pd



import xlsxwriter

urls = [
"https://www.instagram.com/tort.chelyabinsk/",
"https://www.instagram.com/lovecake_74/"
]


def parse():
    dates = []
    for url in urls:
        # проверяем заходит-ли на страницу
        try:
            f = urlopen(url)
            html = f.read()
            soup = BeautifulSoup(html, 'html.parser')
            js = str(soup.find_all("script", type="application/ld+json"))


        except:
            data = "0"

        date = {'ссылка': url}
        date['код'] = js

        #print(js)
        dates.append(date)
        print(js)
    #return dates



def main():
    dates = parse()


if __name__ == '__main__':
    main()

